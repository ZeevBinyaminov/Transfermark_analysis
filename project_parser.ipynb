{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = b\"C:\\Users\\zzbin\\Desktop\\Google Chrome\\chromedriver.exe\"\n",
    "service = Service(PATH)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.transfermarkt.world/wettbewerbe/europa')\n",
    "try:\n",
    "    driver.switch_to.frame(driver.find_elements(By.TAG_NAME, value='iframe')[1])\n",
    "    driver.find_element(By.XPATH, value='/html/body/div/div[2]/div[3]/div[2]/button').click()\n",
    "except (NoSuchElementException, IndexError):\n",
    "    pass\n",
    "\n",
    "def scroll():\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    ActionChains(driver).move_to_element(driver.find_element(By.CSS_SELECTOR, value='#yw1 > div.pager > ul')).perform()\n",
    "    \n",
    "\n",
    "def get_ligues_links():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    trs = soup.find_all('tr', {'class': lambda x: x in ('odd', 'even')})\n",
    "\n",
    "    links = []\n",
    "    for tr in trs:\n",
    "        td = tr.find('td')\n",
    "        table = td.find('table')\n",
    "        tbody = table.find('tbody')\n",
    "        td_link = tbody.find('tr').find_all('td')[1].find('a')\n",
    "        links.append('https://www.transfermarkt.world/' +  td_link.text + '/' + '/'.join(td_link['href'].split('/')[2:]))    \n",
    "    return links\n",
    "\n",
    "scroll()\n",
    "\n",
    "all_leagues_links = []\n",
    "for i in range(2):\n",
    "    \n",
    "    all_leagues_links.extend(get_ligues_links())\n",
    "    try:\n",
    "        next_link = driver.find_element(\n",
    "            By.CSS_SELECTOR,\n",
    "            value='#yw1 > div.pager > ul > li.tm-pagination__list-item.tm-pagination__list-item--icon-next-page > a')\n",
    "        next_link.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    scroll()   \n",
    "        \n",
    "        \n",
    "def get_club_links(league_link):\n",
    "    driver.get(league_link)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')        \n",
    "    trs = soup.find_all('tr', {'class': lambda x: x in ('odd', 'even')})\n",
    "    tds = list(map(lambda x: x.find_all('td')[1], trs))\n",
    "    links = list(\n",
    "        filter(lambda x: 'verein' in x, \n",
    "            list(map(lambda x: 'https://www.transfermarkt.world' + x.find('a', {'href': lambda x: x != '#'})['href'],\n",
    "                     tds))))\n",
    "    return links\n",
    "\n",
    "all_club_links = []\n",
    "for league_link in all_leagues_links:\n",
    "    all_club_links.extend(get_club_links(league_link))      \n",
    "        \n",
    "players_info = {\n",
    "    'Name': [],\n",
    "    'Position': [],\n",
    "    'Age': [],\n",
    "    'Nation': [],\n",
    "    'Height': [],\n",
    "    'Main leg': [], \n",
    "    'Start contract date': [], \n",
    "    'Expiration contract date': [], \n",
    "    'Cost': []\n",
    "    }        \n",
    "\n",
    "\n",
    "def get_club_info(club_link):\n",
    "    global players_info\n",
    "    driver.get(club_link)\n",
    "    driver.find_element(By.XPATH, value='/html/body/div[2]/div[6]/div[1]/div[1]/div[3]/a[2]/div/span').click()\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    trs = soup.find_all('tr', {'class': lambda x: x in ('odd', 'even')})\n",
    "    pattern1 = re.compile(r'.+\\((\\d+)\\)')\n",
    "    pattern2 = re.compile(r'\\s+')\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        tbody = tds[1].find('table').find('tbody')\n",
    "        tbody_trs = tbody.find_all('tr')\n",
    "        players_info['Name'].append(re.sub(pattern1, ' ', tbody_trs[0].find_all('td')[1].text).strip())\n",
    "        players_info['Position'].append(re.sub(pattern2, ' ', tbody_trs[1].find('td').text).strip())\n",
    "        try:\n",
    "            players_info['Age'].append(int(re.match(pattern1, tds[5].text).group(1)))\n",
    "        except AttributeError:\n",
    "            players_info['Age'].append('-')\n",
    "        players_info['Nation'].append([i['title'] for i in tds[6].find_all('img')])\n",
    "        players_info['Height'].append(tds[7].text)\n",
    "        players_info['Main leg'].append('L' if tds[8].text == 'левая' else 'R')\n",
    "        players_info['Start contract date'].append(tds[9].text)\n",
    "        players_info['Expiration contract date'].append(tds[11].text)\n",
    "        players_info['Cost'].append(tds[12].text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for club_link in all_club_links:\n",
    "    get_club_info(club_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(players_info)\n",
    "df_info.to_excel('Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w+') as f:\n",
    "    f.write(json.dumps(players_info))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5446dcbb0f2df12f743acade3cf2cdaf2a348c67ba351a3a9921d96789447493"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
